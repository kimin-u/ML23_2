{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "열일곱번째 제출 23.11.29\n",
    "###### 전처리 : /255\n",
    "###### pca : 256\n",
    "###### svm (c = 16)\n",
    "###### 이미지 증강(좌, 우 쉬프트 >>  180000)\n",
    "###### 쉬프트 정도 조정 (0.10)\n",
    "\n",
    "###### ++ 부류 6 추가학습 svc 합치기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과: 81.55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/user/.local/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/user/.local/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/.local/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/user/.local/lib/python3.10/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/user/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in /home/user/.local/lib/python3.10/site-packages (4.1.0)\n",
      "Requirement already satisfied: scipy in /home/user/.local/lib/python3.10/site-packages (from lightgbm) (1.11.4)\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.10/site-packages (from lightgbm) (1.24.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /home/user/.local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: scipy in /home/user/.local/lib/python3.10/site-packages (from xgboost) (1.11.4)\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.10/site-packages (from xgboost) (1.24.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/user/.local/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/user/.local/lib/python3.10/site-packages (from opencv-python) (1.24.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/user/.local/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.24.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: packaging in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (60.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/user/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/user/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/user/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/user/.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/user/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/user/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/user/.local/lib/python3.10/site-packages (4.65.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/user/.local/lib/python3.10/site-packages (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user/.local/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/user/.local/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/user/.local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/user/.local/lib/python3.10/site-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/user/.local/lib/python3.10/site-packages (from matplotlib) (4.43.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/.local/lib/python3.10/site-packages (from matplotlib) (0.12.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn\n",
    "!pip install scikit-learn\n",
    "\n",
    "# lightgbm\n",
    "!pip install lightgbm\n",
    "\n",
    "# xgboost\n",
    "!pip install xgboost\n",
    "\n",
    "# OpenCV\n",
    "!pip install opencv-python\n",
    "\n",
    "# tensorflow (이미지 데이터 제너레이션을 사용하기 위해)\n",
    "!pip install tensorflow\n",
    "\n",
    "# tqdm\n",
    "!pip install tqdm\n",
    "\n",
    "# matplotlib\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('/home/user/다운로드/test/fashion-mnist_train.csv')\n",
    "\n",
    "train_y = training_data['label']\n",
    "\n",
    "train_X = training_data.drop('label',axis=1)\n",
    "\n",
    "# # 데이터에서 한 줄을 뽑아와서 28x28 크기의 이미지로 변환\n",
    "# sample_image = train_X.iloc[0].values.reshape(28, 28)\n",
    "\n",
    "# # 시각화\n",
    "# plt.imshow(sample_image, cmap='gray')\n",
    "# plt.title(f\"Label: {train_y.iloc[0]}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:09<00:00, 6475.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.10,\n",
    "    height_shift_range=0.10\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data augmentation and adding to the training set loop\n",
    "aug_train_X = []\n",
    "aug_train_y = []\n",
    "\n",
    "for index, row in tqdm(train_X.iterrows(), total=len(train_X)):\n",
    "    random_num = np.random.random()\n",
    "\n",
    "    img = row.values.reshape((28, 28, 1))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Original data\n",
    "    aug_train_X.append(img_array[0])\n",
    "    aug_train_y.append(train_y[index])\n",
    "\n",
    "    # Augmented data with 2/3 probability\n",
    "    \n",
    "    augmented_img_array = next(datagen.flow(img_array, batch_size=1))\n",
    "    augmented_img_array = augmented_img_array.squeeze(axis=0)\n",
    "    aug_train_X.append(augmented_img_array)\n",
    "    aug_train_y.append(train_y[index])\n",
    "\n",
    "print(len(aug_train_X))\n",
    "print(len(aug_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:09<00:00, 6505.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of aug_train_X: (180000, 28, 28, 1)\n",
      "Shape of aug_train_y: (180000,)\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(train_X.iterrows(), total=len(train_X)):\n",
    "    random_num = np.random.random()\n",
    "\n",
    "    img = row.values.reshape((28, 28, 1))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Original data\n",
    "    # aug_train_X.append(img_array[0])\n",
    "    # aug_train_y.append(train_y[index])\n",
    "\n",
    "    augmented_img_array = next(datagen.flow(img_array, batch_size=1))\n",
    "    augmented_img_array = augmented_img_array.squeeze(axis=0)\n",
    "    aug_train_X.append(augmented_img_array)\n",
    "    aug_train_y.append(train_y[index])\n",
    "    \n",
    "# Convert the lists to numpy arrays\n",
    "aug_train_X = np.array(aug_train_X)\n",
    "aug_train_y = np.array(aug_train_y)\n",
    "\n",
    "# Check the shape of the new arrays\n",
    "print(\"Shape of aug_train_X:\", aug_train_X.shape)\n",
    "print(\"Shape of aug_train_y:\", aug_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_X = aug_train_X.reshape((aug_train_X.shape[0], -1))\n",
    "aug_train_X/=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(aug_train_X.shape)\n",
    "# aug_train_X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA( n_components= 256 )\n",
    "aug_train_X = pca.fit_transform(aug_train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 테스트 LGB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65280\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 256\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM 모델 초기화 및 학습\n",
    "\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(aug_train_X, aug_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing: 100%|██████████| 10000/10000 [00:00<00:00, 49004.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "pca 적용\n",
      "(10000, 256)\n"
     ]
    }
   ],
   "source": [
    "test_data_folder = \"/home/user/다운로드/test/public_test_dataset/data\"\n",
    "\n",
    "# 테스트 데이터 로드 및 전처리\n",
    "test_X = []\n",
    "file_names = []\n",
    "\n",
    "print(len(os.listdir(test_data_folder)))\n",
    "\n",
    "# tqdm으로 래핑\n",
    "for file_name in tqdm(os.listdir(test_data_folder), desc=\"Loading and preprocessing\"):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(test_data_folder, file_name)\n",
    "            try:\n",
    "                image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image_array = image / 255.0  # 0부터 1사이의 값\n",
    "                test_X.append(image_array.flatten())  # 2D 배열을 1D로 펼침\n",
    "                # print(image_array)\n",
    "\n",
    "                file_names.append(file_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "# NumPy 배열로 변환\n",
    "test_X = np.array(test_X)\n",
    "print(test_X.shape)\n",
    "\n",
    "if len(test_X) == 0:\n",
    "    print(\"No valid test images found.\")\n",
    "else:\n",
    "    print(\"pca 적용\")\n",
    "    test_X = pca.transform(test_X)\n",
    "    print(test_X.shape)\n",
    "\n",
    "    # 테스트 데이터에 대한 예측\n",
    "    final_predictions = model.predict(test_X)\n",
    "\n",
    "\n",
    "with open('/home/user/다운로드/test/testResultLgb.txt', 'w') as file:\n",
    "    for i, pred in enumerate(final_predictions):\n",
    "        file.write(f\"{i:05d} {pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Class         | AP            |\n",
      "|---------------|---------------|\n",
      "| T-shirt/top   | 0.012         |\n",
      "| Trouser       | 0.008         |\n",
      "| Pullover      | 0.008         |\n",
      "| Dress         | 0.014         |\n",
      "| Coat          | 0.013         |\n",
      "| Sandal        | 0.009         |\n",
      "| Shirt         | 0.012         |\n",
      "| Sneaker       | 0.009         |\n",
      "| Bag           | 0.010         |\n",
      "| Ankle boot    | 0.008         |\n",
      "| mAP           | 0.010         |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "\n",
    "testResult_path = \"/home/user/다운로드/test/testResultLgb.txt\"\n",
    "label_path = \"/home/user/다운로드/test/public_test_dataset/label.txt\"\n",
    "\n",
    "# pred에 해당하는 testResult.txt 파일 읽어오는 부분입니다.\n",
    "with open(testResult_path, 'r') as file1:\n",
    "    preds = file1.readlines()\n",
    "\n",
    "# 정답에 해당하는 label.txt 파일 읽어오는 부분입니다.\n",
    "with open(label_path, 'r') as file2:\n",
    "    labels = file2.readlines()\n",
    "\n",
    "\n",
    "# pred와 label의 클래스값만 리스트로 변환하는 부분입니다.\n",
    "p = np.array([pred.strip().split()[1] for pred in preds])\n",
    "l = np.array([label.strip().split()[1] for label in labels])\n",
    "\n",
    "# pred의 클래스 개수를 count하는 부분입니다.\n",
    "predict_label_count_dict = Counter(p)\n",
    "predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "## mAP 계산하는 부분입니다.\n",
    "AP = []\n",
    "num_class = 10\n",
    "\n",
    "# 모든 클래스에 대해 반복\n",
    "for c, freq in predict_label_count_dict.items() :\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "\n",
    "    temp_precision = []\n",
    "    temp_recall = []\n",
    "\n",
    "    for i in range(len(p)):\n",
    "        # TP, FN 계산\n",
    "        if l[i] == c and p[i] == c :\n",
    "            TP += 1\n",
    "        elif l[i] != c and p[i] == c :\n",
    "            FN += 1\n",
    "\n",
    "        # preciison, recall 계산\n",
    "        if TP+FN != 0:\n",
    "            temp_precision.append(TP/(TP+FN))\n",
    "            temp_recall.append(TP/freq)\n",
    "\n",
    "    # AP 배열에 클래스 각각의 AP value 저장\n",
    "    # auc : preciison-recall curve의 면적 구해줌\n",
    "    AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "mAP = sum(AP) / num_class\n",
    "\n",
    "# 각각의 클래스에 대한 AP와 mAP의 Table 출력 부분입니다.\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "table = \"| {:<13} | {:<13} |\\n\".format(\"Class\", \"AP\") + \"|---------------|---------------|\\n\"\n",
    "\n",
    "for c_name, ap in zip(class_name, AP):\n",
    "    table += \"| {:<13} | {:<13.3f} |\\n\".format(c_name, ap)\n",
    "\n",
    "table += \"| {:<13} | {:<13.3f} |\\n\".format(\"mAP\", mAP)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('../testResult17(다반1조).txt', 'w') as file:\n",
    "#     for i, pred in enumerate(final_predictions):\n",
    "#         file.write(f\"{i:05d} {pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print(final_predictions[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
