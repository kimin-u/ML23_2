{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "열일곱번째 제출 23.11.29\n",
    "###### 전처리 : /255\n",
    "###### pca : 256\n",
    "###### svm (c = 16)\n",
    "###### 이미지 증강(좌, 우 쉬프트 >>  180000)\n",
    "###### 쉬프트 정도 조정 (0.10)\n",
    "\n",
    "###### ++ 부류 6 추가학습 svc 합치기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과: 81.55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('/home/user/다운로드/test/fashion-mnist_train.csv')\n",
    "\n",
    "train_y = training_data['label']\n",
    "\n",
    "train_X = training_data.drop('label',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:27<00:00, 2154.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.10,\n",
    "    height_shift_range=0.10\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data augmentation and adding to the training set loop\n",
    "aug_train_X = []\n",
    "aug_train_y = []\n",
    "\n",
    "for index, row in tqdm(train_X.iterrows(), total=len(train_X)):\n",
    "    random_num = np.random.random()\n",
    "\n",
    "    img = row.values.reshape((28, 28, 1))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Original data\n",
    "    aug_train_X.append(img_array[0])\n",
    "    aug_train_y.append(train_y[index])\n",
    "\n",
    "    # Augmented data with 2/3 probability\n",
    "    \n",
    "    augmented_img_array = next(datagen.flow(img_array, batch_size=1))\n",
    "    augmented_img_array = augmented_img_array.squeeze(axis=0)\n",
    "    aug_train_X.append(augmented_img_array)\n",
    "    aug_train_y.append(train_y[index])\n",
    "\n",
    "print(len(aug_train_X))\n",
    "print(len(aug_train_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:17<00:00, 3341.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of aug_train_X: (180000, 28, 28, 1)\n",
      "Shape of aug_train_y: (180000,)\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(train_X.iterrows(), total=len(train_X)):\n",
    "    random_num = np.random.random()\n",
    "\n",
    "    img = row.values.reshape((28, 28, 1))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Original data\n",
    "    # aug_train_X.append(img_array[0])\n",
    "    # aug_train_y.append(train_y[index])\n",
    "\n",
    "    augmented_img_array = next(datagen.flow(img_array, batch_size=1))\n",
    "    augmented_img_array = augmented_img_array.squeeze(axis=0)\n",
    "    aug_train_X.append(augmented_img_array)\n",
    "    aug_train_y.append(train_y[index])\n",
    "    \n",
    "# Convert the lists to numpy arrays\n",
    "aug_train_X = np.array(aug_train_X)\n",
    "aug_train_y = np.array(aug_train_y)\n",
    "\n",
    "# Check the shape of the new arrays\n",
    "print(\"Shape of aug_train_X:\", aug_train_X.shape)\n",
    "print(\"Shape of aug_train_y:\", aug_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_X = aug_train_X.reshape((aug_train_X.shape[0], -1))\n",
    "aug_train_X/=255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(aug_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA( n_components= 256 )\n",
    "aug_train_X = pca.fit_transform(aug_train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 테스트 XGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost 모델 초기화 및 학습\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "model.fit(aug_train_X , aug_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing:   0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing: 100%|██████████| 15000/15000 [00:02<00:00, 6845.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 784)\n",
      "pca 적용\n",
      "(15000, 256)\n"
     ]
    }
   ],
   "source": [
    "test_data_folder = \"/home/user/다운로드/test/public_test_dataset/data\"\n",
    "\n",
    "# 테스트 데이터 로드 및 전처리\n",
    "test_X = []\n",
    "file_names = []\n",
    "\n",
    "print(len(os.listdir(test_data_folder)))\n",
    "\n",
    "# tqdm으로 래핑\n",
    "for file_name in tqdm(os.listdir(test_data_folder), desc=\"Loading and preprocessing\"):\n",
    "    if file_name.endswith(\".png\"):\n",
    "        file_path = str(test_data_folder) + \"/\" + str(file_name)\n",
    "        try:\n",
    "\n",
    "            img_array = np.fromfile(file_path, np.uint8)\n",
    "            img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
    "            image_array = img / 255.0  # 0부터 1사이의 값\n",
    "            test_X.append(image_array.flatten())  # 2D 배열을 1D로 펼침\n",
    "\n",
    "            file_names.append(file_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "# NumPy 배열로 변환\n",
    "test_X = np.array(test_X)\n",
    "print(test_X.shape)\n",
    "\n",
    "if len(test_X) == 0:\n",
    "    print(\"No valid test images found.\")\n",
    "else:\n",
    "    print(\"pca 적용\")\n",
    "    test_X = pca.transform(test_X)\n",
    "    print(test_X.shape)\n",
    "\n",
    "    # 테스트 데이터에 대한 예측\n",
    "    final_predictions = model.predict(test_X)\n",
    "\n",
    "\n",
    "with open('/home/user/다운로드/test/testResultXgb.txt', 'w') as file:\n",
    "    for i, pred in enumerate(final_predictions):\n",
    "        file.write(f\"{i:05d} {pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "from collections import Counter\n",
    "\n",
    "testResult_path = \"/home/user/다운로드/test/testResultXgb.txt\"\n",
    "label_path = \"/home/user/다운로드/test/public_test_dataset/label.txt\"\n",
    "\n",
    "# pred에 해당하는 testResult.txt 파일 읽어오는 부분입니다.\n",
    "with open(testResult_path, 'r') as file1:\n",
    "    preds = file1.readlines()\n",
    "\n",
    "# 정답에 해당하는 label.txt 파일 읽어오는 부분입니다.\n",
    "with open(label_path, 'r') as file2:\n",
    "    labels = file2.readlines()\n",
    "\n",
    "\n",
    "# pred와 label의 클래스값만 리스트로 변환하는 부분입니다.\n",
    "p = np.array([pred.strip().split()[1] for pred in preds])\n",
    "l = np.array([label.strip().split()[1] for label in labels])\n",
    "\n",
    "# pred의 클래스 개수를 count하는 부분입니다.\n",
    "predict_label_count_dict = Counter(p)\n",
    "predict_label_count_dict = dict(sorted(predict_label_count_dict.items()))\n",
    "\n",
    "## mAP 계산하는 부분입니다.\n",
    "AP = []\n",
    "num_class = 10\n",
    "\n",
    "# 모든 클래스에 대해 반복\n",
    "for c, freq in predict_label_count_dict.items() :\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "\n",
    "    temp_precision = []\n",
    "    temp_recall = []\n",
    "\n",
    "    for i in range(len(p)):\n",
    "        # TP, FN 계산\n",
    "        if l[i] == c and p[i] == c :\n",
    "            TP += 1\n",
    "        elif l[i] != c and p[i] == c :\n",
    "            FN += 1\n",
    "\n",
    "        # preciison, recall 계산\n",
    "        if TP+FN != 0:\n",
    "            temp_precision.append(TP/(TP+FN))\n",
    "            temp_recall.append(TP/freq)\n",
    "\n",
    "    # AP 배열에 클래스 각각의 AP value 저장\n",
    "    # auc : preciison-recall curve의 면적 구해줌\n",
    "    AP.append(auc(temp_recall, temp_precision))\n",
    "\n",
    "mAP = sum(AP) / num_class\n",
    "\n",
    "# 각각의 클래스에 대한 AP와 mAP의 Table 출력 부분입니다.\n",
    "class_name = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "table = \"| {:<13} | {:<13} |\\n\".format(\"Class\", \"AP\") + \"|---------------|---------------|\\n\"\n",
    "\n",
    "for c_name, ap in zip(class_name, AP):\n",
    "    table += \"| {:<13} | {:<13.3f} |\\n\".format(c_name, ap)\n",
    "\n",
    "table += \"| {:<13} | {:<13.3f} |\\n\".format(\"mAP\", mAP)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('../testResult17(다반1조).txt', 'w') as file:\n",
    "#     for i, pred in enumerate(final_predictions):\n",
    "#         file.write(f\"{i:05d} {pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "6\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "0\n",
      "8\n",
      "7\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     print(final_predictions[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
