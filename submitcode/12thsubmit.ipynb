{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "열두번째 제출 23.11.26\n",
    "###### 전처리 : /255\n",
    "###### pca : 256\n",
    "###### svm (c = 16)\n",
    "###### 이미지 증강(좌, 우 쉬프트 >> 약 120000장 학습)\n",
    "###### 쉬프트 정도 조정 (0.10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과: 80.76\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../../archive/fashion-mnist_train.csv')\n",
    "\n",
    "train_y = training_data['label']\n",
    "\n",
    "train_X = training_data.drop('label',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:15<00:00, 3882.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of aug_train_X: (120000, 28, 28, 1)\n",
      "Shape of aug_train_y: (120000,)\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.10,\n",
    "    height_shift_range=0.10\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data augmentation and adding to the training set loop\n",
    "aug_train_X = []\n",
    "aug_train_y = []\n",
    "\n",
    "for index, row in tqdm(train_X.iterrows(), total=len(train_X)):\n",
    "    random_num = np.random.random()\n",
    "\n",
    "    img = row.values.reshape((28, 28, 1))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Original data\n",
    "    aug_train_X.append(img_array[0])\n",
    "    aug_train_y.append(train_y[index])\n",
    "\n",
    "    # Augmented data with 2/3 probability\n",
    "    \n",
    "    augmented_img_array = next(datagen.flow(img_array, batch_size=1))\n",
    "    augmented_img_array = augmented_img_array.squeeze(axis=0)\n",
    "    aug_train_X.append(augmented_img_array)\n",
    "    aug_train_y.append(train_y[index])\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "aug_train_X = np.array(aug_train_X)\n",
    "aug_train_y = np.array(aug_train_y)\n",
    "\n",
    "# Check the shape of the new arrays\n",
    "print(\"Shape of aug_train_X:\", aug_train_X.shape)\n",
    "print(\"Shape of aug_train_y:\", aug_train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train_X = aug_train_X.reshape((aug_train_X.shape[0], -1))\n",
    "aug_train_X/=255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(aug_train_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 256 )\n",
    "aug_train_X = pca.fit_transform(aug_train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=16)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(gamma='scale', kernel='rbf', C=16)\n",
    "svc.fit(aug_train_X, aug_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing:   0%|          | 0/15000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing: 100%|██████████| 15000/15000 [01:55<00:00, 129.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 784)\n",
      "pca 적용\n",
      "(15000, 256)\n"
     ]
    }
   ],
   "source": [
    "test_data_folder = \"../../dataset/private_test_dataset/data/\"\n",
    "\n",
    "# 테스트 데이터 로드 및 전처리\n",
    "test_X = []\n",
    "file_names = []\n",
    "\n",
    "print(len(os.listdir(test_data_folder)))\n",
    "# tqdm으로 래핑\n",
    "for file_name in tqdm(os.listdir(test_data_folder), desc=\"Loading and preprocessing\"):\n",
    "    if file_name.endswith(\".png\"):\n",
    "        file_path = os.path.join(test_data_folder, file_name)\n",
    "        try:\n",
    "            image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image_array = image / 255.0  # 0부터 1사이의 값\n",
    "            test_X.append(image_array.flatten())  # 2D 배열을 1D로 펼침\n",
    "            \n",
    "            file_names.append(file_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "# NumPy 배열로 변환\n",
    "test_X = np.array(test_X)\n",
    "print(test_X.shape)\n",
    "\n",
    "if len(test_X) == 0:\n",
    "    print(\"No valid test images found.\")\n",
    "else:\n",
    "    print(\"pca 적용\")\n",
    "    test_X_pca = pca.transform(test_X)\n",
    "    print(test_X_pca.shape)\n",
    "\n",
    "    predictions = svc.predict(test_X_pca)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../testResult12(다반1조).txt', 'w') as file:\n",
    "    for i, pred in enumerate(predictions):\n",
    "        file.write(f\"{i:05d} {pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "6\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "0\n",
      "8\n",
      "7\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
