{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../archive/fashion-mnist_train.csv')\n",
    "\n",
    "train_y = training_data['label']\n",
    "\n",
    "train_X = training_data.drop('label',axis=1)\n",
    "\n",
    "test_data = pd.read_csv('../archive/fashion-mnist_test.csv')\n",
    "\n",
    "test_y = test_data['label']\n",
    "\n",
    "test_X = test_data.drop('label',axis=1)\n",
    "\n",
    "#label\n",
    "# 0 T-shirt/top\n",
    "# 1 Trouser\n",
    "# 2 Pullover\n",
    "# 3 Dress\n",
    "# 4 Coat\n",
    "# 5 Sandal\n",
    "# 6 Shirt\n",
    "# 7 Sneaker\n",
    "# 8 Bag\n",
    "# 9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalization\n",
    "train_X = train_X / 255.0\n",
    "test_X = test_X /255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = train_X.iloc[12151].values.reshape(28, 28)  \n",
    "\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title(f'Label: {train_y.iloc[0]}') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모델별로 파라미터 바꿔보면서 앙상블도 해보고 score 가장 높은거 기록해두기! !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9089\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='scale', kernel='rbf', C=8)\n",
    "svc.fit(train_X, train_y)\n",
    "\n",
    "accuracy = svc.score(test_X, test_y)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM(C=8) : 0.9089~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.909\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(gamma='scale', kernel='rbf', C=20)\n",
    "svc.fit(train_X, train_y)\n",
    "\n",
    "accuracy = svc.score(test_X, test_y)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svc(C=20) : 0.909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8832"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 랜덤 포레스트 모델 생성 및 훈련\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(train_X, train_y)\n",
    "\n",
    "rf_model.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤포레스트 정확도( 트리 개수 100)  : 0.8866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앙상블 모델의 정확도: 0.8954\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [('svm', svc), ('random_forest', rf_model)]\n",
    "\n",
    "ensemble_model = VotingClassifier(models, voting='hard')\n",
    "\n",
    "# 앙상블 모델 훈련\n",
    "ensemble_model.fit(train_X, train_y)\n",
    "\n",
    "# 앙상블 모델 평가\n",
    "ensemble_accuracy = ensemble_model.score(test_X, test_y)\n",
    "print(f'앙상블 모델의 정확도: {ensemble_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블 ( 랜덤포레스트 + svm ) (hard voting) : 0.8968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\82102\\OneDrive\\Desktop\\ssu\\23_2\\ml\\teamp\\ML23_2\\draft.ipynb 셀 13\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ensemble_model\u001b[39m.\u001b[39mfit(train_X, train_y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# 앙상블 모델 평가\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m ensemble_accuracy \u001b[39m=\u001b[39m ensemble_model\u001b[39m.\u001b[39;49mscore(test_X, test_y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m앙상블 모델의 정확도: \u001b[39m\u001b[39m{\u001b[39;00mensemble_accuracy\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:705\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 705\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_voting.py:366\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    364\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoting \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msoft\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 366\u001b[0m     maj \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# 'hard' voting\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_voting.py:407\u001b[0m, in \u001b[0;36mVotingClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \n\u001b[0;32m    395\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[39m    Weighted average probability for each class per sample.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    405\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    406\u001b[0m avg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage(\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collect_probas(X), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights_not_none\n\u001b[0;32m    408\u001b[0m )\n\u001b[0;32m    409\u001b[0m \u001b[39mreturn\u001b[39;00m avg\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_voting.py:382\u001b[0m, in \u001b[0;36mVotingClassifier._collect_probas\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_collect_probas\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    381\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([clf\u001b[39m.\u001b[39mpredict_proba(X) \u001b[39mfor\u001b[39;00m clf \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_voting.py:382\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_collect_probas\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    381\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray([clf\u001b[39m.\u001b[39;49mpredict_proba(X) \u001b[39mfor\u001b[39;00m clf \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_available_if.py:31\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m     25\u001b[0m attr_err \u001b[39m=\u001b[39m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m     26\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(owner\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribute_name)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m     \u001b[39m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[39m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck(obj):\n\u001b[0;32m     32\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[0;32m     33\u001b[0m     out \u001b[39m=\u001b[39m MethodType(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:827\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_proba\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    826\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobability:\n\u001b[1;32m--> 827\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    828\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpredict_proba is not available when  probability=False\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    829\u001b[0m         )\n\u001b[0;32m    830\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mc_svc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnu_svc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    831\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpredict_proba only implemented for SVC and NuSVC\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "models = [('svm', svc), ('random_forest', rf_model)]\n",
    "\n",
    "ensemble_model = VotingClassifier(models, voting='soft')\n",
    "\n",
    "# 앙상블 모델 훈련\n",
    "ensemble_model.fit(train_X, train_y)\n",
    "\n",
    "# 앙상블 모델 평가\n",
    "ensemble_accuracy = ensemble_model.score(test_X, test_y)\n",
    "print(f'앙상블 모델의 정확도: {ensemble_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블 ( 랜덤포레스트 + svm ) (soft voting) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 모델의 정확도: 0.8565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter=100)\n",
    "\n",
    "# 모델 훈련\n",
    "logistic_regression_model.fit(train_X, train_y)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions = logistic_regression_model.predict(test_X)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = (predictions == test_y).mean()\n",
    "print(f'로지스틱 회귀 모델의 정확도: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀 정확도 \n",
    "##### epoch 20 : 0.81,\n",
    "##### epoch 100 : 0.8544,\n",
    "##### epoch 150 : 0.8541\n",
    "##### epoch 250 : 0.8492,\n",
    "##### epoch 500 : 0.8467,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3개 모델 앙상블 모델의 정확도: 0.898\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [('svm', svc), ('random_forest', rf_model), ('logistic_regression', logistic_regression_model)]\n",
    "\n",
    "ensemble_model = VotingClassifier(models, voting='hard')\n",
    "\n",
    "# 앙상블 모델 훈련\n",
    "ensemble_model.fit(train_X, train_y)\n",
    "\n",
    "# 앙상블 모델 평가\n",
    "ensemble_accuracy = ensemble_model.score(test_X, test_y)\n",
    "print(f'3개 모델 앙상블 모델의 정확도: {ensemble_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\82102\\OneDrive\\Desktop\\ssu\\23_2\\ml\\teamp\\ML23_2\\draft.ipynb 셀 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gb_model \u001b[39m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# 모델 학습\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m gb_model\u001b[39m.\u001b[39;49mfit(train_X, train_y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# 테스트 데이터로 예측\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/82102/OneDrive/Desktop/ssu/23_2/ml/teamp/ML23_2/draft.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_pred_gb \u001b[39m=\u001b[39m gb_model\u001b[39m.\u001b[39mpredict(test_X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:525\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    524\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 525\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    526\u001b[0m     X,\n\u001b[0;32m    527\u001b[0m     y,\n\u001b[0;32m    528\u001b[0m     raw_predictions,\n\u001b[0;32m    529\u001b[0m     sample_weight,\n\u001b[0;32m    530\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    531\u001b[0m     X_val,\n\u001b[0;32m    532\u001b[0m     y_val,\n\u001b[0;32m    533\u001b[0m     sample_weight_val,\n\u001b[0;32m    534\u001b[0m     begin_at_stage,\n\u001b[0;32m    535\u001b[0m     monitor,\n\u001b[0;32m    536\u001b[0m )\n\u001b[0;32m    538\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:603\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    596\u001b[0m         initial_loss \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    597\u001b[0m             y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    598\u001b[0m             raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    599\u001b[0m             sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    600\u001b[0m         )\n\u001b[0;32m    602\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    604\u001b[0m     i,\n\u001b[0;32m    605\u001b[0m     X,\n\u001b[0;32m    606\u001b[0m     y,\n\u001b[0;32m    607\u001b[0m     raw_predictions,\n\u001b[0;32m    608\u001b[0m     sample_weight,\n\u001b[0;32m    609\u001b[0m     sample_mask,\n\u001b[0;32m    610\u001b[0m     random_state,\n\u001b[0;32m    611\u001b[0m     X_csc,\n\u001b[0;32m    612\u001b[0m     X_csr,\n\u001b[0;32m    613\u001b[0m )\n\u001b[0;32m    615\u001b[0m \u001b[39m# track loss\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    242\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    244\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[1;32m--> 245\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    247\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[0;32m    248\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    249\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[0;32m    250\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[0;32m    258\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "gb_model.fit(train_X, train_y)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred_gb = gb_model.predict(test_X)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_gb = accuracy_score(test_y, y_pred_gb)\n",
    "print(f'그라디언트 부스팅 모델의 정확도: {accuracy_gb * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;merror&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;merror&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='merror',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False,objective=\"multi:softmax\",eval_metric=\"merror\")\n",
    "xgb.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost  모델의 정확도: 0.9063  \n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 예측\n",
    "y_pred_xgb = xgb.predict(test_X)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy_xgb = accuracy_score(test_y, y_pred_xgb)\n",
    "print(f'xgboost  모델의 정확도: {accuracy_xgb}  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앙상블 모델의 정확도: 0.9098\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [('svm', svc), ('xgb', xgb)]\n",
    "\n",
    "ensemble_model = VotingClassifier(models, voting='hard')\n",
    "\n",
    "# 앙상블 모델 훈련\n",
    "ensemble_model.fit(train_X, train_y)\n",
    "\n",
    "# 앙상블 모델 평가\n",
    "ensemble_accuracy = ensemble_model.score(test_X, test_y)\n",
    "print(f'앙상블 모델의 정확도: {ensemble_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앙상블 모델의 정확도: 0.9103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [('svm', svc),('randomforest', rf_model), ('xgb', xgb)]\n",
    "\n",
    "ensemble_model = VotingClassifier(models, voting='hard')\n",
    "\n",
    "# 앙상블 모델 훈련\n",
    "ensemble_model.fit(train_X, train_y)\n",
    "\n",
    "# 앙상블 모델 평가\n",
    "ensemble_accuracy = ensemble_model.score(test_X, test_y)\n",
    "print(f'앙상블 모델의 정확도: {ensemble_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앙상블 모델의 정확도: 0.9045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = [('svm', svc),('randomforest', rf_model), ('xgb', xgb),('lr',logistic_regression_model)]\n",
    "\n",
    "ensemble_model = VotingClassifier(models, voting='hard')\n",
    "\n",
    "# 앙상블 모델 훈련\n",
    "ensemble_model.fit(train_X, train_y)\n",
    "\n",
    "# 앙상블 모델 평가\n",
    "ensemble_accuracy = ensemble_model.score(test_X, test_y)\n",
    "print(f'앙상블 모델의 정확도: {ensemble_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(gamma='scale',kernel='rbf',C=8)\n",
    "\n",
    "cv_results = cross_validate(svc, train_X, train_y, cv=3)\n",
    "\n",
    "print(f\"Validation acc for each fold: {cv_results['test_score']}\")\n",
    "print(f\"Mean acc:  {mean(cv_results['test_score'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
